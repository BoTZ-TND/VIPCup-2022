{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install kornia\n",
    "# ! pip install -U albumentations[imgaug]\n",
    "# ! pip install neptune-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment training dataset build by using \n",
    " 2000 Synthetic images from [Impaintin](https://www.grip.unina.it/download/vipcup2022/gated_convolution_inpainting.zip) dataset | places in the folder names \"Generated\" \\\n",
    " and 5000 real images from [COCO2017](http://images.cocodataset.org/zips/val2017.zip) dataset | placed in the folder name \"Real\"\n",
    "\n",
    "data set folder structure\n",
    "```\n",
    "|SampleData |- label.csv\n",
    "            |- Generated /\n",
    "            |- Real /\n",
    "```\n",
    "\n",
    "__Download & save the backborne model before any experiment run ; \\\n",
    "xception model : http://data.lip6.fr/cadene/pretrainedmodels/xception-43020ad28.pth \\\n",
    "and save in the 'C:\\Users\\deela\\.cache\\torch\\hub\\checkpoints' directory__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\deela\\anaconda3\\lib\\site-packages\\albumentations\\imgaug\\transforms.py:263: FutureWarning: IAAAdditiveGaussianNoise is deprecated. Please use GaussNoise instead\n",
      "  warnings.warn(\"IAAAdditiveGaussianNoise is deprecated. Please use GaussNoise instead\", FutureWarning)\n",
      "c:\\Users\\deela\\anaconda3\\lib\\site-packages\\albumentations\\augmentations\\transforms.py:778: FutureWarning: JpegCompression has been deprecated. Please use ImageCompression\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "import warnings\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.multiprocessing as mp\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.distributed as dist\n",
    "from models.MAT import MAT\n",
    "# from datasets.dataset import DeepfakeDataset\n",
    "from AGDA import AGDA\n",
    "import cv2\n",
    "from utils import dist_average,ACC\n",
    "from config import train_config\n",
    "import neptune.new as neptune\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from datasets.augmentations import augmentations\n",
    "from albumentations import CenterCrop,Compose,Resize,RandomCrop\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "cv2.setNumThreads(0)\n",
    "cv2.ocl.setUseOpenCL(False)\n",
    "# GPU settings\n",
    "assert torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/Botz/VIPCup-logs/e/VIP-2\n",
      "Remember to stop your run once youâ€™ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    }
   ],
   "source": [
    "run = neptune.init(\n",
    "    project=\"Botz/VIPCup-logs\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJkNWJjMDdhNC05NWY5LTQwNWQtYTQyNi0zNjNmYmYwZDg3M2YifQ==\",\n",
    ")  # your credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepfakeDataset(Dataset):\n",
    "    def __init__(self, df, resize=(320,320), augment='augment0', normalize=dict(mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5]), phase='train'):\n",
    "        self.df = df \n",
    "        self.aug=augmentations[augment]\n",
    "        self.file_paths = self.df['file_path'].values \n",
    "        self.labels = self.df['label'].values \n",
    "        self.trans=Compose([RandomCrop(*resize),ToTensorV2()])\n",
    "        self.phase = phase\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.file_paths[idx]\n",
    "        image_label = self.labels[idx]\n",
    "        image = cv2.cvtColor(cv2.imread(image_path, 1), cv2.COLOR_RGB2BGR)\n",
    "        # orig_image = torch.from_numpy(np.transpose(image, (2,0,1)))\n",
    "        # resized_image = Resize(size=self.image_size)(orig_image)\n",
    "#         return {'image': resized_image, 'label': torch.from_numpy(image_label)}\n",
    "        image=self.aug(image=image)['image']\n",
    "        final_image = self.trans(image=image)['image']\n",
    "        return final_image, torch.from_numpy(np.array(image_label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def next_epoch(self):\n",
    "        self.epoch+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_path = './data/SampleData/labels.csv'\n",
    "ann_df = pd.read_csv(ann_path)\n",
    "X, y = ann_df.iloc[:, :-1], ann_df.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=0dd9087b-bcff-45ec-8e71-f2b40db80bf8 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('0dd9087b-bcff-45ec-8e71-f2b40db80bf8').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imageId</th>\n",
       "      <th>file_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5516</th>\n",
       "      <td>000000407518</td>\n",
       "      <td>./data/SampleData\\Real\\000000407518.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3266</th>\n",
       "      <td>000000149568</td>\n",
       "      <td>./data/SampleData\\Real\\000000149568.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6468</th>\n",
       "      <td>000000517832</td>\n",
       "      <td>./data/SampleData\\Real\\000000517832.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4752</th>\n",
       "      <td>000000319100</td>\n",
       "      <td>./data/SampleData\\Real\\000000319100.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2958</th>\n",
       "      <td>000000113403</td>\n",
       "      <td>./data/SampleData\\Real\\000000113403.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "           imageId                                file_path  label\n",
       "5516  000000407518  ./data/SampleData\\Real\\000000407518.jpg      0\n",
       "3266  000000149568  ./data/SampleData\\Real\\000000149568.jpg      0\n",
       "6468  000000517832  ./data/SampleData\\Real\\000000517832.jpg      0\n",
       "4752  000000319100  ./data/SampleData\\Real\\000000319100.jpg      0\n",
       "2958  000000113403  ./data/SampleData\\Real\\000000113403.jpg      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = X_train.copy()\n",
    "train_df['label'] = y_train\n",
    "\n",
    "eval_df = X_test.copy()\n",
    "eval_df['label'] = y_test\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_state(net,ckpt):\n",
    "    sd=net.state_dict()\n",
    "    nd={}\n",
    "    goodmatch=True\n",
    "    for i in ckpt:\n",
    "        if i in sd and sd[i].shape==ckpt[i].shape:\n",
    "            nd[i]=ckpt[i]\n",
    "            #print(i)\n",
    "        else:\n",
    "            print('fail to load %s'%i)\n",
    "            goodmatch=False\n",
    "    net.load_state_dict(nd,strict=False)\n",
    "    return goodmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loss(loss_pack,config):\n",
    "    if 'loss' in loss_pack:\n",
    "        return loss_pack['loss']\n",
    "    loss=config.ensemble_loss_weight*loss_pack['ensemble_loss']+config.aux_loss_weight*loss_pack['aux_loss']\n",
    "    if config.AGDA_loss_weight!=0:\n",
    "        loss+=config.AGDA_loss_weight*loss_pack['AGDA_ensemble_loss']+config.match_loss_weight*loss_pack['match_loss']\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_step(logs,data_loader,net,optimizer,device,config,AG=None,phase='train'):\n",
    "    if config.AGDA_loss_weight==0:\n",
    "        AG=None\n",
    "    recorder={}\n",
    "    if config.feature_layer=='logits':\n",
    "        record_list=['loss','acc']\n",
    "    else:\n",
    "        record_list=['ensemble_loss','aux_loss','ensemble_acc']\n",
    "        if AG is not None:\n",
    "            record_list+=['AGDA_ensemble_loss','match_loss']\n",
    "    for i in record_list:\n",
    "        recorder[i]=dist_average(device)\n",
    "    # begin training\n",
    "    start_time = time.time()\n",
    "    if phase=='train':\n",
    "        net.train()\n",
    "    else: net.eval()\n",
    "    with tqdm(data_loader, unit=\"batch\") as tepoch:\n",
    "        for X, y in tepoch:\n",
    "            X = X.float().to(device)\n",
    "            y = y.to(device)\n",
    "            with torch.set_grad_enabled(phase=='train'):\n",
    "                with autocast():\n",
    "                    loss_pack=net(X,y,train_batch=True,AG=AG)\n",
    "            if phase=='train':\n",
    "                batch_loss = train_loss(loss_pack,config)\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            with torch.no_grad():\n",
    "                if config.feature_layer=='logits':\n",
    "                    loss_pack['acc']=ACC(loss_pack['logits'],y)\n",
    "                else:\n",
    "                    loss_pack['ensemble_acc']=ACC(loss_pack['ensemble_logit'],y)\n",
    "            for i in record_list:\n",
    "                recorder[i].step(loss_pack[i])\n",
    "            tepoch.set_postfix({r : recorder[r].get() for r in record_list})\n",
    "                \n",
    "\n",
    "    # end of this epoch\n",
    "    batch_info=[]\n",
    "    for i in record_list:\n",
    "        mesg=recorder[i].get()\n",
    "        logs[i]=mesg\n",
    "        batch_info.append('{}:{:.4f}'.format(i,mesg))\n",
    "    end_time = time.time()\n",
    "\n",
    "    # write log for this epoch\n",
    "    if phase == 'train':\n",
    "        for i in record_list:\n",
    "            run[f'train/{i}'].log(recorder[i].get())\n",
    "    else:\n",
    "        for i in record_list:\n",
    "            run[f'eval/{i}'].log(recorder[i].get())\n",
    "    logging.info('{}: {}, Time {:3.2f}'.format(phase,'  '.join(batch_info), end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_worker(config):\n",
    "    # rank=local_rank+rank_offset\n",
    "    logging.basicConfig(\n",
    "    filename=os.path.join('runs', config.name,'train.log'),\n",
    "    filemode='a',\n",
    "    format='%(asctime)s: %(levelname)s: [%(filename)s:%(lineno)d]: %(message)s',\n",
    "    level=logging.INFO)\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    # dist.init_process_group(backend='nccl', init_method=config.url,world_size=world_size, rank=rank)\n",
    "    # if rank==0:\n",
    "    #     try:\n",
    "    #         os.remove('/tmp/.pytorch_distribute')\n",
    "    #     except:\n",
    "    #         pass\n",
    "    np.random.seed(1234567)\n",
    "    torch.manual_seed(1234567)\n",
    "    torch.cuda.manual_seed(1234567)\n",
    "    # torch.cuda.set_device(local_rank)\n",
    "\n",
    "    print(\"Start Data preparation ...\")\n",
    "    train_dataset = DeepfakeDataset(phase='train',**config.train_dataset)\n",
    "    validate_dataset=DeepfakeDataset(phase='test',**config.val_dataset)\n",
    "    # train_sampler=torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
    "    # validate_sampler=torch.utils.data.distributed.DistributedSampler(validate_dataset)\n",
    "    train_loader=torch.utils.data.DataLoader(train_dataset, batch_size=config.batch_size, pin_memory=True)\n",
    "    validate_loader=torch.utils.data.DataLoader(validate_dataset, batch_size=config.batch_size, pin_memory=True)\n",
    "    print(\"Successfully complete Data preparation ...\")\n",
    "    logs = {}\n",
    "    start_epoch = 0\n",
    "    net = MAT(**config.net_config)\n",
    "    for i in config.freeze:\n",
    "        if 'backbone' in i:\n",
    "            net.net.requires_grad_(False)\n",
    "        elif 'attention' in i:\n",
    "            net.attentions.requires_grad_(False)\n",
    "        elif 'feature_center' in i:\n",
    "            net.auxiliary_loss.alpha=0\n",
    "        elif 'texture_enhance' in i:\n",
    "            net.texture_enhance.requires_grad_(False)\n",
    "        elif 'fcs' in i:\n",
    "            net.projection_local.requires_grad_(False)\n",
    "            net.project_final.requires_grad_(False)\n",
    "            net.ensemble_classifier_fc.requires_grad_(False)\n",
    "        else:\n",
    "            if 'xception' in str(type(net.net)):\n",
    "                for j in net.net.seq:\n",
    "                    if j[0]==i:\n",
    "                        for t in j[1]:\n",
    "                            t.requires_grad_(False)\n",
    "            \n",
    "            if 'EfficientNet' in str(type(net.net)):\n",
    "                if i=='b0':\n",
    "                    net.net._conv_stem.requires_grad_(False)\n",
    "                stage_map=net.net.stage_map\n",
    "                for c in range(len(stage_map)-2,-1,-1):\n",
    "                    if not stage_map[c]:\n",
    "                        stage_map[c]=stage_map[c+1]\n",
    "                for c1,c2 in zip(stage_map,net.net._blocks):\n",
    "                    if c1==i:\n",
    "                        c2.requires_grad_(False)\n",
    "    print(\"Model Initialzation ...\")\n",
    "    # net=nn.SyncBatchNorm.convert_sync_batchnorm(net)#.to(local_rank)\n",
    "    net.to(DEVICE)\n",
    "    AG=AGDA(**config.AGDA_config)#.to(local_rank)\n",
    "    optimizer = torch.optim.AdamW(net.parameters(), lr=config.learning_rate, betas=config.adam_betas, weight_decay=config.weight_decay)\n",
    "    scheduler=torch.optim.lr_scheduler.StepLR(optimizer, step_size=config.scheduler_step, gamma=config.scheduler_gamma)\n",
    "    if config.ckpt:\n",
    "        loc = DEVICE\n",
    "        checkpoint = torch.load(config.ckpt, map_location=loc)\n",
    "        logs = checkpoint['logs']\n",
    "        start_epoch = int(logs['epoch'])+1\n",
    "        if load_state(net.module,checkpoint['state_dict']) and config.resume_optim:\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
    "            try:\n",
    "                scheduler.load_state_dict(checkpoint['scheduler_state'])\n",
    "            except:\n",
    "                pass\n",
    "        else:\n",
    "            net.module.auxiliary_loss.alpha=torch.tensor(config.alpha)\n",
    "        del checkpoint\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"Start Model Training ...\")\n",
    "    for epoch in range(start_epoch, config.epochs):\n",
    "        print(f'[EPOCH] - {epoch}')\n",
    "        logs['epoch'] = epoch\n",
    "        # train_sampler.set_epoch(epoch)\n",
    "        # train_sampler.dataset.next_epoch()\n",
    "        run_step(logs=logs,data_loader=train_loader,net=net,optimizer=optimizer,device=DEVICE,config=config,AG=AG,phase='train')\n",
    "        run_step(logs=logs,data_loader=validate_loader,net=net,optimizer=optimizer,device=DEVICE,config=config,phase='valid')\n",
    "        net.auxiliary_loss.alpha*=config.alpha_decay # because of 'module' not found error.\n",
    "        scheduler.step()\n",
    "    else :\n",
    "        torch.save({\n",
    "                'logs': logs,\n",
    "                'state_dict': net.state_dict(),\n",
    "                'optimizer_state': optimizer.state_dict(),\n",
    "                'scheduler_state':scheduler.state_dict()}, 'checkpoints/'+config.name+'/ckpt_%s.pth'%epoch)\n",
    "        # dist.barrier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distributed_train(config,world_size=0,num_gpus=0,rank_offset=0):\n",
    "    if not num_gpus:\n",
    "        num_gpus = torch.cuda.device_count()\n",
    "    if not world_size:\n",
    "        world_size=num_gpus\n",
    "    mp.spawn(main_worker, nprocs=num_gpus, args=(world_size,rank_offset,config))\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"Model-Name\": 'multi-attention model',\n",
    "    'Dataset-Name': 'Custome-testing',\n",
    "    \"attention_layer\": \"b5\",\n",
    "    \"batch_size\": 16,\n",
    "    \"Augmentations\": \"horiz. flip, random crop\",\n",
    "    \"learning_rate\": 0.001, \n",
    "    \"optimizer\": \"AdamW\",\n",
    "}\n",
    "run[\"parameters\"] = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Data preparation ...\n",
      "Successfully complete Data preparation ...\n",
      "Model Initialzation ...\n",
      "Start Model Training ...\n",
      "[EPOCH] - 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [01:16<00:00,  1.15batch/s, loss=0.427, acc=0.806]\n",
      "train: loss:0.4269  acc:0.8061, Time 76.28\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:33<00:00,  2.60batch/s, loss=0.177, acc=0.952]\n",
      "valid: loss:0.1769  acc:0.9517, Time 33.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH] - 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [01:17<00:00,  1.13batch/s, loss=0.158, acc=0.95] \n",
      "train: loss:0.1576  acc:0.9503, Time 77.74\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:34<00:00,  2.53batch/s, loss=0.063, acc=0.989] \n",
      "valid: loss:0.0630  acc:0.9893, Time 34.80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH] - 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [01:22<00:00,  1.06batch/s, loss=0.0618, acc=0.984]\n",
      "train: loss:0.0618  acc:0.9837, Time 82.78\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:33<00:00,  2.64batch/s, loss=0.0248, acc=0.995]\n",
      "valid: loss:0.0248  acc:0.9950, Time 33.34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH] - 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [01:22<00:00,  1.07batch/s, loss=0.0347, acc=0.99] \n",
      "train: loss:0.0347  acc:0.9901, Time 82.06\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:40<00:00,  2.18batch/s, loss=0.022, acc=0.995] \n",
      "valid: loss:0.0220  acc:0.9950, Time 40.46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH] - 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [01:29<00:00,  1.02s/batch, loss=0.023, acc=0.996] \n",
      "train: loss:0.0230  acc:0.9964, Time 89.61\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:41<00:00,  2.12batch/s, loss=0.0115, acc=0.998] \n",
      "valid: loss:0.0115  acc:0.9979, Time 41.45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for the remaining 22 operations to synchronize with Neptune. Do not kill this process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 22 operations synced, thanks for waiting!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://app.neptune.ai/Botz/VIPCup-logs/e/VIP-2\n"
     ]
    }
   ],
   "source": [
    "name='Efb4'\n",
    "url='tcp://127.0.0.1:27015'\n",
    "Config=train_config(name,['custom'],url=url, df=train_df, eval_df=eval_df, attention_layer='b5',feature_layer='logits',epochs=5,batch_size=16,AGDA_loss_weight=0, augment='augment0')\n",
    "Config.mkdirs()\n",
    "main_worker(Config) \n",
    "run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08aea5f70877f29c16b88dd2c4446bb1b0b98820cbf110aea5656aecf55fbfb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
